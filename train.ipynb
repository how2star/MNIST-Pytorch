{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/5], Step [100/750], Loss: 1.5090\n",
      "Epoch [1/5], Step [200/750], Loss: 0.7578\n",
      "Epoch [1/5], Step [300/750], Loss: 0.5898\n",
      "Epoch [1/5], Step [400/750], Loss: 0.5089\n",
      "Epoch [1/5], Step [500/750], Loss: 0.4377\n",
      "Epoch [1/5], Step [600/750], Loss: 0.4239\n",
      "Epoch [1/5], Step [700/750], Loss: 0.3716\n",
      "----------------------------------------------\n",
      "Epoch [1/5] completed in 19.30 seconds.\n",
      "Validation Loss: 0.3567, Accuracy: 88.76%\n",
      "----------------------------------------------\n",
      "Epoch [2/5], Step [100/750], Loss: 0.3362\n",
      "Epoch [2/5], Step [200/750], Loss: 0.3063\n",
      "Epoch [2/5], Step [300/750], Loss: 0.3012\n",
      "Epoch [2/5], Step [400/750], Loss: 0.2877\n",
      "Epoch [2/5], Step [500/750], Loss: 0.2745\n",
      "Epoch [2/5], Step [600/750], Loss: 0.2535\n",
      "Epoch [2/5], Step [700/750], Loss: 0.2318\n",
      "----------------------------------------------\n",
      "Epoch [2/5] completed in 21.40 seconds.\n",
      "Validation Loss: 0.2469, Accuracy: 92.17%\n",
      "----------------------------------------------\n",
      "Epoch [3/5], Step [100/750], Loss: 0.2341\n",
      "Epoch [3/5], Step [200/750], Loss: 0.2188\n",
      "Epoch [3/5], Step [300/750], Loss: 0.2051\n",
      "Epoch [3/5], Step [400/750], Loss: 0.1978\n",
      "Epoch [3/5], Step [500/750], Loss: 0.1974\n",
      "Epoch [3/5], Step [600/750], Loss: 0.1847\n",
      "Epoch [3/5], Step [700/750], Loss: 0.1917\n",
      "----------------------------------------------\n",
      "Epoch [3/5] completed in 20.87 seconds.\n",
      "Validation Loss: 0.1846, Accuracy: 94.22%\n",
      "----------------------------------------------\n",
      "Epoch [4/5], Step [100/750], Loss: 0.1888\n",
      "Epoch [4/5], Step [200/750], Loss: 0.1843\n",
      "Epoch [4/5], Step [300/750], Loss: 0.1751\n",
      "Epoch [4/5], Step [400/750], Loss: 0.1807\n",
      "Epoch [4/5], Step [500/750], Loss: 0.1796\n",
      "Epoch [4/5], Step [600/750], Loss: 0.1526\n",
      "Epoch [4/5], Step [700/750], Loss: 0.1682\n",
      "----------------------------------------------\n",
      "Epoch [4/5] completed in 89.48 seconds.\n",
      "Validation Loss: 0.1556, Accuracy: 95.33%\n",
      "----------------------------------------------\n",
      "Epoch [5/5], Step [100/750], Loss: 0.1740\n",
      "Epoch [5/5], Step [200/750], Loss: 0.1451\n",
      "Epoch [5/5], Step [300/750], Loss: 0.1616\n",
      "Epoch [5/5], Step [400/750], Loss: 0.1444\n",
      "Epoch [5/5], Step [500/750], Loss: 0.1453\n",
      "Epoch [5/5], Step [600/750], Loss: 0.1537\n",
      "Epoch [5/5], Step [700/750], Loss: 0.1475\n",
      "----------------------------------------------\n",
      "Epoch [5/5] completed in 53.89 seconds.\n",
      "Validation Loss: 0.1425, Accuracy: 95.47%\n",
      "----------------------------------------------\n",
      "##############################################\n",
      "Total training time: 221.75 seconds\n",
      "Accuracy of the model on the test images: 98.03%\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 检查训练设备，优先使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 1. 数据预处理和加载\n",
    "# 定义训练集的数据增强与标准化变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # 随机旋转图像\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),  # 随机平移\n",
    "    transforms.ToTensor(),  # 将图像转为Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 标准化图像，使均值为0.5，标准差为0.5\n",
    "])\n",
    "\n",
    "# 定义测试集的标准化变换\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载并加载训练集和测试集，并划分训练集和验证集\n",
    "full_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=train_transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# 将训练集划分为训练集和验证集\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# 将数据集封装到DataLoader中，以便在训练和测试过程中批量加载\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)  # 训练集，批量大小64\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)  # 验证集，批量大小64\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)  # 测试集，批量大小64\n",
    "\n",
    "# 2. 定义CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 第一层卷积：输入通道1（灰度图像），输出通道32，卷积核大小3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # 第二层卷积：输入通道32，输出通道64，卷积核大小3x3\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # 最大池化层：核大小2x2，步长2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # 全连接层1：将特征图展平到64*7*7，输出128个特征\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        # 全连接层2：输出10个特征（对应10个类别）\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一层卷积、ReLU激活和池化\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        # 第二层卷积、ReLU激活和池化\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        # 将特征展平为1维向量，以便输入到全连接层\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # 第一个全连接层和ReLU激活\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # 第二个全连接层（输出层）\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化CNN模型\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 3. 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类任务\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用Adam优化器，学习率0.001\n",
    "\n",
    "# 4. 开始记录训练时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 训练和验证模型\n",
    "num_epochs = 5  # 训练轮次\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0  # 用于记录每个epoch的总损失\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 将图像和标签移动到训练设备\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 将梯度清零，以便计算新的梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播，计算模型输出\n",
    "        outputs = model(images)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累加损失值\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # 每100个小批次打印一次损失\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 记录每个epoch的训练时间\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print('----------------------------------------------')\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {epoch_duration:.2f} seconds.\")\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "    print('----------------------------------------------')\n",
    "\n",
    "# 训练总时长\n",
    "total_training_time = time.time() - start_time\n",
    "print('##############################################')\n",
    "print(f'Total training time: {total_training_time:.2f} seconds')\n",
    "\n",
    "# 5. 只保存模型的参数\n",
    "torch.save(model.state_dict(), './model/myCNNmodel_MNIST.pth')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "correct = 0  # 记录正确分类的样本数\n",
    "total = 0    # 记录测试集的总样本数\n",
    "\n",
    "# 在测试过程中，不需要计算梯度，使用torch.no_grad()可以加速测试\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # 将图像和标签移动到GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 获取模型输出\n",
    "        outputs = model(images)\n",
    "        # 获取最大值对应的类别\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # 累加正确分类的样本数\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 打印模型的分类准确率\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {test_accuracy:.2f}%')\n",
    "print('##############################################')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
